{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attached-answer",
   "metadata": {},
   "source": [
    "## MPCA implementation w/ Tensorly\n",
    "---\n",
    "### The MPCA objective\n",
    "\n",
    "A set of tensor objects $ \\{X_{1},X_{2},\\ldots,X_{M}\\} $ is availalble for training, where each sample $ X_{i}\\in\\mathbb{R}^{I_{1}xI_{2}x\\cdots xI_{N}},i=1,2,\\ldots,M $. The MPCA objective is to project each sample to $ \\mathbb{R}^{P_{1}xP_{2}x\\cdots xP_{N}} $ with $ P_{i}<I_{i},i=1,\\ldots,N $ such that the projected samples hold as much variation (from the original data) as possible.\n",
    "\n",
    "In order to measure variation, we will employ the **total scatter tensor**:\n",
    "$$ Y_{T}=\\sum_{m=1}^{M}||Y_{m}-\\overline{Y}||_{F}^{2} $$\n",
    "\n",
    ", where $ \\overline{Y} $ denotes the **mean projected tensor** ($ \\overline{Y}=\\frac{1}{M}\\sum_{m=1}^{M}y_{m} $). Therefore, the objective of MPCA is to determine the projection matrices $ U^{(1)},U^{(2)},\\ldots,U^{(N)} $ such that the total scatter is maximized:\n",
    "\n",
    "$$ U^{(1)},U^{(2)},\\ldots,U^{(N)}=\\arg\\max_{U^{(1)},U^{(2)},\\ldots,U^{(N)}}\\sum_{m=1}^{M}||Y_{m}-\\overline{Y}||_{F}^{2} $$\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "**Input:** A set of tensor objects $ \\{X_{1},X_{2},\\ldots,X_{M}\\} $, $ X_{i}\\in\\mathbb{R}^{I_{1}xI_{2}x\\cdots xI_{N}},i=1,2,\\ldots,M $\n",
    "\n",
    "**Output:** $ N $ projection matrices $ U^{(1)},U^{(2)},\\ldots,U^{(N)} $ that project the input tensor objects to lower dimensions while maximizing the total scatter.\n",
    "\n",
    "    1. Center the data\n",
    "    2. Initialize Projection matrices (Full Projection Truncation)\n",
    "    3. MPCA Loop\n",
    "        for k=1:K\n",
    "            for n=1:N\n",
    "                3a. Caclulate the n-mode partial projection # Eq. 6.31 [1] \n",
    "                3b. Calculate the n-mode total scatter # Eq. 6.32 [1]\n",
    "                3c .Set U(n) to be the Pn eigenvectors coresponding to the largest Pn eigenvalues of of the n-mode total scatter\n",
    "\n",
    "### Scatter Maximization - Reconstruction error minimization\n",
    "\n",
    "One can easily prove that **maximizing the scatter** in each mode is actually the same as **minimizing the reconstruction error**. We will follow the **Alternating Partial Projection** logic, fixing all projection matrices but one. The second objective can be formulated as: \n",
    "\n",
    "$$ \\min_{U^{(n)}}||X-Y\\times_{1}U^{(1)}\\times_{2}U^{(2)}\\cdots\\times_{N}U^{(N)}||_{F}^{2} $$\n",
    "where for each projection matric $ U^{(n)}\\in R^{I_{n}\\times P_{n}},U^{(n)^{T}}U^{(n)}=I_{P_{n}} $ is true. Further:\n",
    "$$ \\min_{U^{(n)}}\\sum_{m=1}^{M}||X_{m(n)}-U^{(n)}Y_{m(n)}U_{Φ(n)}^{T}||_{F}^{2}$$\n",
    "$$ =\\min_{U^{(n)}}\\sum_{m=1}^{M}||X_{m(n)}-U^{(n)}U^{(n)^{T}}X_{m(n)}U_{Φ(n)}U_{Φ(n)}^{T}||_{F}^{2} $$\n",
    "\n",
    "The Frobenius norm is **unitary invariant**. This means that the value of the norm is not affected when applying orthogonal transformations (*$ U_{Φ(n)} $ is such transformation as the kronecker product of orthogonal matrices*). Therefore:\n",
    "\n",
    "$$ \\min_{U^{(n)}}\\sum_{m=1}^{M}||X_{m(n)}U_{Φ(n)}-U^{(n)}U^{(n)^{T}}X_{m(n)}U_{Φ(n)}{U_{Φ(n)}^{T}U_{Φ(n)}}||_{F}^{2} $$\n",
    "$$ =\\min_{U^{(n)}}\\sum_{m=1}^{M}||\\hat{Y}_{m(n)}^{(n)}-U^{(n)}U^{(n)^{T}}\\hat{Y}_{m(n)}^{(n)}||_{F}^{2} $$\n",
    "\n",
    "where $ U_{Φ(n)}^{T}U_{Φ(n)}=I_{I_{2}I_{3}...I_{N}} $ and $ \\hat{Y}_{m(n)}^{(n)} $ denotes the partial projection to all modes except the n-th. The last equation, in a sense, is the **PCA objective for the n-th mode of the data**, and the solution is given straight from the SVD of $ \\hat{Y}_{m(n)}^{(n)} $, by setting $ U^{(n)} $ equal to the $P_{n}$ singular vectors corresponding the the $P_{n}$ most siginificant singular values [3].\n",
    "\n",
    "All that remains is proving the first sentance of this section. *Is maximizing the scatter the same as minimizing the reconstruction error?*\n",
    "\n",
    "$$  \\min_{U^{(n)}}||X-Y\\times_{1}U^{(1)}\\times_{2}U^{(2)}\\cdots\\times_{N}U^{(N)}||_{F}^{2} $$\n",
    "\n",
    "$$ =\\min_{U^{(n)}}\\sum_{m=1}^{M}||X_{m(n)}-U^{(n)}Y_{m(n)}U_{Φ(n)}^{T}||_{F}^{2}$$\n",
    "\n",
    "$$ =\\min_{U^{(n)}}\\sum_{m=1}^{M}tr((X_{m(n)}-U^{(n)}Y_{m(n)}U_{Φ(n)}^{T})(X_{m(n)}-U^{(n)}Y_{m(n)}U_{Φ(n)}^{T})^{T}) $$\n",
    "\n",
    "$$ =\\min_{U^{(n)}}\\sum_{m=1}^{M}tr((X_{m(n)}-U^{(n)}Y_{m(n)}U_{Φ(n)})(X_{m(n)}^{T}-U_{Φ(n)}Y_{m(1)}^{T}U^{(n)^{T}})) $$\n",
    "\n",
    "$$ =\\min_{U^{(n)}}\\sum_{m=1}^{M}||X_{m(n)}||^{2}-tr(X_{m(n)}U_{Φ(n)}Y_{m(n)}^{T}U^{(1)^{T}})-tr(U^{(1)}Y_{m(n)}U_{Φ(n)}^{T}X_{m(n)}^{T})+tr(U^{(1)}Y_{m(1)}{U_{Φ(1)}^{T}U_{Φ(1)}}Y_{m(1)}^{T}) $$\n",
    "\n",
    "By leveraging $ tr(ABCD)=tr(DABC) $ we get:\n",
    "\n",
    "$$ \\min_{U^{(n)}}\\sum_{m=1}^{M}||X_{m(n)}||_{F}^{2}-||Y_{m(n)}||_{F}^{2} $$\n",
    "\n",
    "Because $ ||X_{m(1)}||^{2} $ is determined by the data samples, this can be transformed into the following maximization problem:\n",
    "\n",
    "$$ \\max_{U^{(n)}}\\sum_{m=1}^{M}||Y_{m(n)}||_{F}^{2} $$\n",
    "\n",
    "and provided that our data is centered we reach:\n",
    "\n",
    "$$ \\max_{U^{(n)}}\\sum_{m=1}^{M}||Y_{m(n)}-\\overline{Y}_{(n)}||_{F}^{2} $$\n",
    "\n",
    "which is the the **scatter maximization objective**. Therefore, the two objective are interchangable and refer to the same process. This is challenged experimentally in *Example 2*.\n",
    "\n",
    "---\n",
    "#### References\n",
    "[1] Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data, Haiping Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, Chapman & Hall/CRC Press Machine Learning and Pattern Recognition Series, Taylor and Francis, ISBN: 978-1-4398572-4-3, 2013.\n",
    "\n",
    "[2] Haiping Lu, K.N. Plataniotis, and A.N. Venetsanopoulos, \"MPCA: Multilinear Principal Component Analysis of Tensor Objects\", IEEE Transactions on Neural Networks, Vol. 19, No. 1, Page: 18-39, January 2008.\n",
    "\n",
    "[3] The Elements of Statistical Learning (2nd edition), Hastie, Tibshirani and Friedman, Springer-Verlag, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "binding-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import tensorly as tl\n",
    "from scipy.io import loadmat\n",
    "from scipy.linalg import svd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worth-marketplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 22, 10, 731)\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "USF17GAL = tl.tensor(loadmat('USF17Gal.mat')['fea3D'],dtype=np.double)\n",
    "print(USF17GAL.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blessed-simulation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class myMPCA():\n",
    "    '''\n",
    "    An object-oriented implementation of MPCA (Multilinear Principle Component Analysis).\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    __init__(): Initialzies the myMPCA object and handles error-checking on parameters the user has entered.\n",
    "    fit(): Performs MPCA with given arguments on samples.\n",
    "    transform(): Projects and returns the data using the computed projection matrices from fit().\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.maxK: No of iterations (user-defined)\n",
    "    self.Q: Variance percentage to keep (user defined)\n",
    "    self.objective: Objective to solve {error_min} or {scatter_max}\n",
    "    self.sample_modes: # of modes of given dataset\n",
    "    self.sample_dims: # of modes of a sample\n",
    "    self.samples_no: # of samples\n",
    "    self.Ps: The dimensions of the projected samples (list)\n",
    "    self.samples_mean: Mean tensor of input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,Q,maxK,objective):\n",
    "        '''\n",
    "        Q: Percentage of variation to keep\n",
    "        maxK: Maximum number of iterations\n",
    "        objective: Use error minization {error_min} or scatter maximation {scatter_max}. These have the very same results as also shown by example 2.\n",
    "        '''\n",
    "        \n",
    "        # Error handling on input\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            if int(maxK) <= 0:\n",
    "                \n",
    "                raise Exception('Max iters (k) has to be a positive integer.')\n",
    "                \n",
    "            self.maxK = maxK\n",
    "                \n",
    "        except:\n",
    "\n",
    "            raise Exception('Max iters (k) has to be a positive integer.')\n",
    "\n",
    "        try:\n",
    "            \n",
    "            if float(Q) <= 0:\n",
    "            \n",
    "                raise Exception('Q has to be positive.')\n",
    "                \n",
    "            self.Q = Q\n",
    "                \n",
    "        except:\n",
    "\n",
    "            raise Exception('Q has to be a positive integer.')\n",
    "            \n",
    "        if objective == 'error_min' or objective == 'scatter_max':\n",
    "            \n",
    "            self.objective = objective\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            raise Exception('Not valid objective to use. Please use either {error_min} or {scatter_max}')\n",
    "            \n",
    "    def fit(self,samples):\n",
    "        '''\n",
    "        Performs MPCA with given arguments.\n",
    "        samples: Input tensor of (N+1) dimensions (+1: Group input in one larger tensor)\n",
    "        '''\n",
    "        \n",
    "        # Gather and store basic info on the train data\n",
    "    \n",
    "        self.sample_modes = len(samples.shape)\n",
    "    \n",
    "        self.sample_dims = len(samples.shape) - 1\n",
    "\n",
    "        self.samples_no = samples.shape[-1]\n",
    "        \n",
    "        self.Ps = []\n",
    "        \n",
    "        ########################################################\n",
    "        # 1. Center the data\n",
    "        ########################################################\n",
    "        \n",
    "        # Find mean tensor\n",
    "        \n",
    "        self.samples_mean = tl.mean(samples,axis=self.sample_dims)\n",
    "        \n",
    "        # Center the data\n",
    "\n",
    "        for i in range(self.samples_no):\n",
    "\n",
    "            samples[...,i] = np.subtract(samples[...,i],self.samples_mean)\n",
    "     \n",
    "        ########################################################\n",
    "        # 2. Initialize Projecton Matrices\n",
    "        ########################################################\n",
    "        \n",
    "        # Initializing projection matrices according to Full Projection Truncation...\n",
    "\n",
    "        self.projection_matrices = []\n",
    "        self.corresponding_eigenvals = []\n",
    "\n",
    "        for n in range(self.sample_dims):\n",
    "\n",
    "            # Phi (n-mode total scatter matrix has dimensions In x In)\n",
    "\n",
    "            In = samples.shape[n]\n",
    "\n",
    "            phi = np.zeros((In,In))\n",
    "\n",
    "            for m in range(self.samples_no):\n",
    "\n",
    "                # Store the m-th sample in Xm\n",
    "                \n",
    "                Xm = samples[...,m]\n",
    "\n",
    "                # N-mode matricization of Xm\n",
    "\n",
    "                Xm_unfolded = tl.unfold(Xm,mode=n)\n",
    "\n",
    "                # Add Xm x Xm ^ T to Phi\n",
    "\n",
    "                phi = phi + Xm_unfolded @ tl.transpose(Xm_unfolded)\n",
    "\n",
    "            # Solve the eigenvalue problem on Phi\n",
    "\n",
    "            eigenvals, eigenvecs = np.linalg.eig(phi)\n",
    "\n",
    "            # eig doesnt not necessarily return sorted eigenvalues, we need to sort them\n",
    "\n",
    "            indexOrd = np.argsort(eigenvals)[::-1] \n",
    "\n",
    "            eigenvecs_sorted = eigenvecs[:,indexOrd]\n",
    "\n",
    "            eigenvals_sorted = eigenvals[indexOrd]\n",
    "            \n",
    "            # In order to get consistent results, force the first component of\n",
    "            # each eigenvector to be positive\n",
    "\n",
    "            for l in range(eigenvecs_sorted.shape[1]):\n",
    "\n",
    "                if eigenvecs_sorted[0,l] < 0.0:\n",
    "\n",
    "                    eigenvecs_sorted[:,l] = eigenvecs_sorted[:,l] * (-1)\n",
    "\n",
    "            # Store eigenvals and eigenvectors (eigenvectors will compose the initial projection matrices)\n",
    "\n",
    "            self.projection_matrices.append(eigenvecs_sorted)\n",
    "\n",
    "            self.corresponding_eigenvals.append(eigenvals_sorted)\n",
    "                \n",
    "        ########################################################\n",
    "        # 3. Q-Based method (determine projection dimensions)\n",
    "        ########################################################\n",
    "        \n",
    "        # In short, the Q-Based method finds the ratio of the eigenvalues\n",
    "        # after truncation of a number of the least important eigenvalues\n",
    "        # over the sum of all the eigenvalues. This ratio 'explains'\n",
    "        # the remaining scatter in this node. Moreover, we need this\n",
    "        # value to be AT LEAST user-defined Q. Therefore, we truncate as many\n",
    "        # dimensions as possible in respect to this contraint.\n",
    "        \n",
    "        sums = [] # Another way to see this ratio is that of the cumulative distribution of the eigenvalues\n",
    "        \n",
    "        for n in range(self.sample_dims): # In each mode\n",
    "            \n",
    "            # Find the sum of the most significant eigenvalues ...\n",
    "            \n",
    "            In = len(self.corresponding_eigenvals[n])\n",
    "            \n",
    "            sums.append(np.zeros((In,1)))\n",
    "            \n",
    "            sums[n][0] = self.corresponding_eigenvals[n][0]\n",
    "            \n",
    "            sum_per_mode = self.corresponding_eigenvals[n][0]\n",
    "        \n",
    "            for i in range(1,In):\n",
    "                \n",
    "                sums[n][i] = sums[n][i-1] + self.corresponding_eigenvals[n][i]\n",
    "                \n",
    "            # ... over the sum of all the eigenvalues for each mode\n",
    "                \n",
    "            sums[n] = sums[n] / sum(self.corresponding_eigenvals[n])\n",
    "            \n",
    "            # However, we have to keep only the most significant eigenvectors\n",
    "            # so that the ratio is AT LEAST Q\n",
    "            \n",
    "            Ps = np.where(sums[n] >= self.Q/100)\n",
    "            \n",
    "            if self.objective == 'scatter_max':\n",
    "            \n",
    "                self.projection_matrices[n] = self.projection_matrices[n][:,0:(Ps[0][0]+1)] # Truncating columns\n",
    "            \n",
    "            elif self.objective == 'error_min':\n",
    "                \n",
    "                self.projection_matrices[n] = np.transpose(self.projection_matrices[n][:,0:(Ps[0][0]+1)]) # Truncating columns                \n",
    "            \n",
    "            self.Ps.append(Ps[0][0]+1)\n",
    "        \n",
    "        ########################################################\n",
    "        # 4. MPCA Loop\n",
    "        ########################################################\n",
    "        \n",
    "        if self.objective == 'scatter_max':\n",
    "    \n",
    "            for k in range(self.maxK):\n",
    "\n",
    "                for n in range(self.sample_dims):\n",
    "\n",
    "                    In = samples.shape[n]\n",
    "\n",
    "                    phi = np.zeros((In,In))\n",
    "\n",
    "                    for m in range(self.samples_no): # Eq. 6.32 [1]\n",
    "\n",
    "                        # Store the m-th sample in Xm\n",
    "\n",
    "                        Xm = samples[...,m]\n",
    "\n",
    "                        # (Partially) project Xm using the existing projection matrices\n",
    "\n",
    "                        projection_modes = [i for i in range(len(Xm.shape))]\n",
    "\n",
    "                        projection_modes.remove(n) # Without using the current mode!\n",
    "\n",
    "                        projections2use = [self.projection_matrices[i] for i in projection_modes]\n",
    "\n",
    "                        Xm = tl.tenalg.multi_mode_dot(Xm,projections2use,modes=projection_modes,transpose=True)\n",
    "\n",
    "                        # N-mode matricization of Xm\n",
    "\n",
    "                        Xm_unfolded = tl.unfold(Xm,mode=n)\n",
    "\n",
    "                        # Add Xm x Xm ^ T to Phi\n",
    "\n",
    "                        phi = phi + Xm_unfolded @ tl.transpose(Xm_unfolded) \n",
    "\n",
    "                    # phi holds now the complete n-mode scatter matrix\n",
    "                    # Finding the largest eigenvalues and eigenvectors of phi\n",
    "                    # will lead us to the n-mode projetion matrix.\n",
    "\n",
    "                    eigenvals, eigenvecs = np.linalg.eig(phi)\n",
    "\n",
    "                    # eig doesnt not necessarily return sorted eigenvalues, we need to sort them\n",
    "                    # and keep Pn < In of them in the projection matrix.\n",
    "\n",
    "                    indexOrd = np.argsort(eigenvals)[::-1]\n",
    "\n",
    "                    eigenvecs_sorted = eigenvecs[:,indexOrd]\n",
    "\n",
    "                    eigenvecs_truncated = eigenvecs_sorted[:,0:self.Ps[n]]\n",
    "\n",
    "                    eigenvals_sorted = eigenvals[indexOrd]\n",
    "\n",
    "                    eigenvals_truncated = eigenvals_sorted[0:self.Ps[n]]\n",
    "\n",
    "                    # In order to get consistent results, force the first component of\n",
    "                    # each eigenvector to be positive\n",
    "\n",
    "                    for l in range(self.Ps[n]):\n",
    "\n",
    "                        if eigenvecs_truncated[0,l] < 0.0:\n",
    "\n",
    "                            eigenvecs_truncated[:,l] = eigenvecs_truncated[:,l] * (-1)\n",
    "\n",
    "                    # Update projection matrix of this mode\n",
    "\n",
    "                    self.projection_matrices[n] = eigenvecs_truncated\n",
    "                    \n",
    "        elif self.objective == 'error_min':\n",
    "            \n",
    "            # Error minimazation\n",
    "\n",
    "            for k in range(self.maxK):\n",
    "\n",
    "                for n in range(self.sample_dims):\n",
    "\n",
    "                    In = samples.shape[n]\n",
    "\n",
    "                    # Calculate the partial projection\n",
    "\n",
    "                    projection_modes = [i for i in range(self.sample_modes-1)]\n",
    "\n",
    "                    projection_modes.remove(n) # Without using the current mode!\n",
    "\n",
    "                    projections2use = [self.projection_matrices[i] for i in projection_modes]\n",
    "\n",
    "                    partial_projection = tl.tenalg.multi_mode_dot(samples,projections2use,modes=projection_modes,transpose=False)            \n",
    "\n",
    "                    partial_projection_unfolded = np.transpose(tl.unfold(partial_projection,mode=n))\n",
    "\n",
    "                    # Set the U(n) projection matrix equal to Pn first right eigenvectors of Xm_unfolded\n",
    "\n",
    "                    U, s, Vh = svd(partial_projection_unfolded,full_matrices=False)\n",
    "\n",
    "                    right_singular_vecs_truncated = Vh[0:self.Ps[n],:]\n",
    "\n",
    "                    # In order to get consistent results, force the first component of\n",
    "                    # each eigenvector to be positive\n",
    "\n",
    "                    for l in range(self.Ps[n]):\n",
    "\n",
    "                        if right_singular_vecs_truncated[l,0] < 0.0:\n",
    "\n",
    "                            right_singular_vecs_truncated[l,:] = right_singular_vecs_truncated[l,:] * (-1)                    \n",
    "\n",
    "                    # Update projection matrix of this mode\n",
    "\n",
    "                    self.projection_matrices[n] = right_singular_vecs_truncated\n",
    "\n",
    "\n",
    "    def transform(self,samples):\n",
    "        '''\n",
    "        Projects and returns the data using the computed projection \n",
    "        matrices from fit().\n",
    "        '''\n",
    "        \n",
    "        if self.objective == 'scatter_max':\n",
    "        \n",
    "            projected_data = tl.tenalg.multi_mode_dot(samples,self.projection_matrices,transpose=True)\n",
    "        \n",
    "        elif self.objective == 'error_min':\n",
    "            \n",
    "            projected_data = tl.tenalg.multi_mode_dot(samples,self.projection_matrices,transpose=False)            \n",
    "        \n",
    "        return projected_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-lloyd",
   "metadata": {},
   "source": [
    "---\n",
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wicked-ordinary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-mode projection matrix shape: (32, 26)\n",
      "1-mode projection matrix shape: (22, 15)\n",
      "2-mode projection matrix shape: (10, 10)\n",
      "Initial tensor size (w/ samples): (32, 22, 10, 731)\n",
      "Projected tensor size (w/ samples): (26, 15, 10, 731)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "\n",
    "# Create a myMPCA object and fit the dataset\n",
    "\n",
    "mpca = myMPCA(97,10,'scatter_max')\n",
    "mpca.fit(USF17GAL)\n",
    "\n",
    "# Print projection matrix sizes\n",
    "\n",
    "for n in range(len(mpca.projection_matrices)):\n",
    "    print(f'{n}-mode projection matrix shape: {mpca.projection_matrices[n].shape}')\n",
    "    \n",
    "# Print initial tensor size and projected tensor size\n",
    "\n",
    "print(f'Initial tensor size (w/ samples): {USF17GAL.shape}');\n",
    "\n",
    "projected_data = mpca.transform(USF17GAL)\n",
    "\n",
    "print(f'Projected tensor size (w/ samples): {projected_data.shape}');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "referenced-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||T_error_min - T_scatter_max||= 2.142162928584675e-11\n",
      "\n",
      "0-mode projection matrix : 1.684525025500799e-13\n",
      "1-mode projection matrix : 1.585987509423577e-13\n",
      "2-mode projection matrix : 7.057462914935218e-14\n",
      "\n",
      "\n",
      "mode-3 projection matrix of error_min approach\n",
      "----------------------------------------------\n",
      "[[ 0.27384955  0.0174603   0.4914432   0.45367813  0.34185165  0.53956814\n",
      "   0.19236548  0.17076755  0.03812933  0.04177432]\n",
      " [ 0.34598142  0.26084022  0.43993326  0.25336088 -0.07724821 -0.47558074\n",
      "  -0.3543072  -0.40272969 -0.11536558 -0.14610915]\n",
      " [ 0.37110676  0.35589344  0.18531734 -0.26713846 -0.36380175 -0.19323186\n",
      "   0.22434981  0.50023961  0.2204387   0.33325392]\n",
      " [ 0.38696814  0.31480832 -0.14028795 -0.41717297 -0.07905606  0.38233954\n",
      "   0.2130531  -0.25294391 -0.29465835 -0.45695538]\n",
      " [ 0.38619683  0.15722878 -0.4016527  -0.08956554  0.38164136  0.14983162\n",
      "  -0.38485447 -0.22021594  0.26968532  0.46834432]\n",
      " [ 0.36359073 -0.07245699 -0.44128997  0.31590269  0.24795888 -0.31897545\n",
      "   0.0048743   0.48320309 -0.11004622 -0.39896406]\n",
      " [ 0.30662882 -0.3240406  -0.25633405  0.361874   -0.38117541 -0.03888133\n",
      "   0.45380713 -0.35267718 -0.15167181  0.32277488]\n",
      " [ 0.24775026 -0.4401855   0.03523199 -0.00860283 -0.47164553  0.28262824\n",
      "  -0.4248681   0.07624652  0.41560703 -0.28663107]\n",
      " [ 0.20941505 -0.45173068  0.20127618 -0.32833488  0.08960188 -0.00200253\n",
      "  -0.26135596  0.2030071  -0.64380554  0.2678282 ]\n",
      " [ 0.19296741 -0.41604808  0.21770809 -0.37140422  0.39454044 -0.30590484\n",
      "   0.3726124  -0.20258345  0.3933964  -0.14299987]]\n",
      "\n",
      "\n",
      "mode-3 projection matrix of scatter_max approach\n",
      "------------------------------------------------\n",
      "[[ 0.27384955  0.0174603   0.4914432   0.45367813  0.34185165  0.53956814\n",
      "   0.19236548  0.17076755  0.03812933  0.04177432]\n",
      " [ 0.34598142  0.26084022  0.43993326  0.25336088 -0.07724821 -0.47558074\n",
      "  -0.3543072  -0.40272969 -0.11536558 -0.14610915]\n",
      " [ 0.37110676  0.35589344  0.18531734 -0.26713846 -0.36380175 -0.19323186\n",
      "   0.22434981  0.50023961  0.2204387   0.33325392]\n",
      " [ 0.38696814  0.31480832 -0.14028795 -0.41717297 -0.07905606  0.38233954\n",
      "   0.2130531  -0.25294391 -0.29465835 -0.45695538]\n",
      " [ 0.38619683  0.15722878 -0.4016527  -0.08956554  0.38164136  0.14983162\n",
      "  -0.38485447 -0.22021594  0.26968532  0.46834432]\n",
      " [ 0.36359073 -0.07245699 -0.44128997  0.31590269  0.24795888 -0.31897545\n",
      "   0.0048743   0.48320309 -0.11004622 -0.39896406]\n",
      " [ 0.30662882 -0.3240406  -0.25633405  0.361874   -0.38117541 -0.03888133\n",
      "   0.45380713 -0.35267718 -0.15167181  0.32277488]\n",
      " [ 0.24775026 -0.4401855   0.03523199 -0.00860283 -0.47164553  0.28262824\n",
      "  -0.4248681   0.07624652  0.41560703 -0.28663107]\n",
      " [ 0.20941505 -0.45173068  0.20127618 -0.32833488  0.08960188 -0.00200253\n",
      "  -0.26135596  0.2030071  -0.64380554  0.2678282 ]\n",
      " [ 0.19296741 -0.41604808  0.21770809 -0.37140422  0.39454044 -0.30590484\n",
      "   0.3726124  -0.20258345  0.3933964  -0.14299987]]\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "\n",
    "# Create 2 MPCA object for the two objectives and fit the dataset\n",
    "\n",
    "mpca_error_min = myMPCA(98,10,'error_min')\n",
    "mpca_scatter_max = myMPCA(98,10,'scatter_max')\n",
    "\n",
    "mpca_error_min.fit(USF17GAL)\n",
    "mpca_scatter_max.fit(USF17GAL)\n",
    "\n",
    "# Project the data\n",
    "\n",
    "projected_data_error_min = mpca_error_min.transform(USF17GAL)\n",
    "projected_data_scatter_max = mpca_scatter_max.transform(USF17GAL)\n",
    "\n",
    "# and print the norm of the distance between the results of each objective\n",
    "\n",
    "print(f'||T_error_min - T_scatter_max||= {tl.norm(projected_data_error_min-projected_data_scatter_max)}\\n')\n",
    "\n",
    "# along with the norm of the distance between projection matrices\n",
    "\n",
    "for n in range(len(mpca_error_min.projection_matrices)):\n",
    "    print(f'{n}-mode projection matrix : {tl.norm(np.transpose(mpca_error_min.projection_matrices[n])-mpca_scatter_max.projection_matrices[n])}')\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "# Finally, print the mode-3 projection matrix of each approach\n",
    "\n",
    "print('mode-3 projection matrix of error_min approach\\n----------------------------------------------')\n",
    "print(mpca_scatter_max.projection_matrices[2])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('mode-3 projection matrix of scatter_max approach\\n------------------------------------------------')\n",
    "print(np.transpose(mpca_error_min.projection_matrices[2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
