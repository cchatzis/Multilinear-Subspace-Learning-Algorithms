{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-orientation",
   "metadata": {},
   "source": [
    "## R-UMLDA implementation w/ Tensorly\n",
    "---\n",
    "### The R-UMLDA Objective\n",
    "\n",
    "A set of tensor objects $ \\{X_{1},X_{2},\\ldots,X_{M}\\} $ is availalble for training, where each sample $ X_{i}\\in\\mathbb{R}^{I_{1}xI_{2}x\\cdots xI_{N}},i=1,2,\\ldots,M $ and there exits $c$ classes. The R-UMLDA objective is to project each sample using **$ P $ EMPs** so that\n",
    "\n",
    "* Fisher's discrimination criterion (FDC) for each of the p EMPs is maximized ($ \\frac{S_{B}}{S_{W}} $)\n",
    "* the coordinate vectors/projected features ($ g_{p}\\in\\mathbb{R}^{M},p=1,2,\\ldots,P $) are all uncorellated.\n",
    "\n",
    "In short, for the p-th EMP (data is centered):\n",
    "$$ u_{p}^{(1)},u_{p}^{(2)},\\ldots,u_{p}^{(N)}=\\arg\\max_{u_{p}^{(1)},u_{p}^{(2)},\\ldots,u_{p}^{(N)}}\\frac{S_{B}}{S_{W}}=\\frac{\\sum_{c=1}^{C}M_{c}\\overline{y_{c_{p}}}^{2}}{\\sum_{m=1}^{M}(y_{m_{p}}-\\overline{y_{c_{mp}}})^{2}}  $$\n",
    "subject to:\n",
    "$$ \\frac{g_{p}^{T}g_{q}}{||g_{p}||||g_{q}||}=δ_{pq}=\\begin{cases}\n",
    "1 & p=q\\\\\n",
    "0 & otherwise\n",
    "\\end{cases},\\,p,q=1,\\ldots,P $$\n",
    "where: \n",
    "\n",
    "$ M_{c} $ denotes the number of samples beloning in class $c$,\n",
    "\n",
    "$ y_{c_{p}} $ denotes the mean of the projected feature of samples belonging in $c$ using the p-th EMP,\n",
    "\n",
    "$ \\overline{y_{c_{mp}}} $ denotes the mean of the projected features of samples belonging to the same class $c$ as the m-th sample using the p-th EMP and\n",
    "\n",
    "$ y_{m_{p}} $ denotes the (scalar) projection of the m-th sample using the p-th EMP.\n",
    "\n",
    "Moreover, we will employ regularizaton in order to:\n",
    "* Counter the effects of the SSS scenario and\n",
    "* Improve the generalization capabilities\n",
    "\n",
    "Just as before, we cannot solve directly for all of the N projection vectors of an EMP. Assuming we are solving for the n-th mode projetion vector of the p-th EMP, the optimization problem becomes:\n",
    "\n",
    "$$ u_{p}^{(n)}=\\arg\\max_{u_{p}^{(n)}}\\frac{u_{p}^{(n)^{T}}S_{B}^{(n)}u_{p}^{(n)}}{u_{p}^{(n)^{T}}S_{W}^{(n)}u_{p}^{(n)}}=\\frac{(u_{p}^{(n)^{T}})\\sum_{c=1}^{C}M_{c}\\overline{y_{c_{p}}^{(n)}}\\overline{y_{c_{p}}^{(n)^{T}}}u_{p}^{(n)}}{(u_{p}^{(n)^{T}})(\\sum_{m=1}^{M}(y_{m_{p}}^{(n)}-\\overline{y_{c_{mp}}^{(n)}})(y_{m_{p}}^{(n)}-\\overline{y_{c_{mp}}^{(n)}})^{T}+γλ_{max}(S_{w}^{(n)})I_{I_{n}})(u_{p}^{(n)})} $$\n",
    "subject to:\n",
    "$$ u_{p}^{(n)^{T}}Y_{p}^{(n)}g_{q}=0\\, q=1,2,\\ldots,p-1 $$\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "$ (n) $ denotes partial projection to all modes except the n-th,\n",
    "\n",
    "$ S_{w}^{(n)}=\\sum_{m=1}^{M}(X_{m(n)}-X_{c_{m}(n)})(X_{m(n)}-X_{c_{m}(n)})^{T} $ denotes the within-class scatter for the n-mode vectors of the training samples,\n",
    "\n",
    "$ γ $ is the regularization hyperparameter,\n",
    "\n",
    "$ I_{I_{n}} $ is the $I_{n}xI_{n} $ identity matrix,\n",
    "\n",
    "$ Y_{p}^{(n)}=\\left[\\begin{array}{cccc}\n",
    "y_{1p}^{(n)} & y_{2p}^{(n)} & \\cdots & y_{Mp}^{(n)}\\end{array}\\right]\\in\\mathbb{R}^{I_{n}xM} $ (partial projection of all samples using all projection vectors but the n-th) and\n",
    "\n",
    "$ g_{p} $ denotes the p-th coordinate vector ($ g_{p}=Y_{p}^{(n)^{T}}u_{p}^{(n)} $).\n",
    "\n",
    "Solution: Eq. 11 [2]\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "**Input:**  A set of tensor objects $ \\{X_{1},X_{2},\\ldots,X_{M}\\} $, $ X_{i}\\in\\mathbb{R}^{I_{1}xI_{2}x\\cdots xI_{N}},i=1,2,\\ldots,M $\n",
    "\n",
    "**Output:** The TVP $ u_{p}^{(n)},p=1,2,\\ldots,P,n=1,2,\\ldots,N $ that separate classes as best as possible according to the FDC,  while producing uncorellated features.\n",
    "\n",
    "    1. Center the data\n",
    "    2. Initialize Projection matrices\n",
    "    3. Estimate largest eigenvalue of n-mode within class scatter\n",
    "    4. UMLDA Loop\n",
    "        for p=1:P\n",
    "            for k=1:K\n",
    "                for n=1:N\n",
    "                    4a. Calculate partial projection\n",
    "                    4b. Calculate Rp, BCS, WCS\n",
    "                    4c. Set U(n) to be the eigenvector respective to the largest eigenvalue of WCS^(-1) @ Rp @ BCS\n",
    "---\n",
    "#### References\n",
    "[1] Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data, Haiping Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, Chapman & Hall/CRC Press Machine Learning and Pattern Recognition Series, Taylor and Francis, ISBN: 978-1-4398572-4-3, 2013.\n",
    "\n",
    "[2] Haiping Lu, K.N. Plataniotis, and A.N. Venetsanopoulos, Uncorrelated Multilinear Discriminant Analysis with Regularization and Aggregation for Tensor Object Recognition\", IEEE Transactions on Neural Networks, Vol. 20, No. 1, Page: 103-123, Jan. 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fleet-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import tensorly as tl\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import numpy as np\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sonic-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (1145, 1024)\n",
      "After reshaping: (32, 32, 1145)\n",
      "Train set shape: (32, 32, 320)\n",
      "Test set shape: (32, 32, 825)\n"
     ]
    }
   ],
   "source": [
    "# Import and reshape dataset\n",
    "\n",
    "FERETC80A45S6 = tl.tensor(loadmat('FERETC80A45S6/FERETC80A45S6_32x32.mat')['fea'],dtype=np.double)\n",
    "FERETC80A45S6_labels = tl.tensor(loadmat('FERETC80A45S6/FERETC80A45S6_32x32.mat')['gnd'],dtype=np.double)\n",
    "\n",
    "print(f'Initial shape: {FERETC80A45S6.shape}')\n",
    "\n",
    "# Transpose to make sure the number of samples is the last dim!\n",
    "\n",
    "FERETC80A45S6 = copy.deepcopy(np.transpose(FERETC80A45S6))\n",
    "FERETC80A45S6 = copy.deepcopy(FERETC80A45S6.reshape(32,32,FERETC80A45S6.shape[-1]))\n",
    "\n",
    "for i in range(FERETC80A45S6.shape[-1]): \n",
    "    FERETC80A45S6[:,:,i] = copy.deepcopy(np.transpose(FERETC80A45S6[:,:,i]))\n",
    "\n",
    "print(f'After reshaping: {FERETC80A45S6.shape}')\n",
    "\n",
    "# Load train-test subset\n",
    "\n",
    "trainIdx = tl.tensor(loadmat('FERETC80A45S6/4Train/1.mat')['trainIdx'])\n",
    "testIdx = tl.tensor(loadmat('FERETC80A45S6/4Train/1.mat')['testIdx'])\n",
    "\n",
    "# squeeze to skips dims with 1 component (e.g. (32, 32, 320, 1)->(32, 32, 320))\n",
    "\n",
    "train_set = np.squeeze(FERETC80A45S6[:,:,trainIdx-1],-1) \n",
    "test_set = np.squeeze(FERETC80A45S6[:,:,testIdx-1],-1)\n",
    "\n",
    "gnd_train = np.squeeze(FERETC80A45S6_labels[trainIdx-1])\n",
    "gnd_test = np.squeeze(FERETC80A45S6_labels[testIdx-1])\n",
    "\n",
    "print(f'Train set shape: {train_set.shape}')\n",
    "print(f'Test set shape: {test_set.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "plastic-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRUMLDA():\n",
    "    '''\n",
    "    An object-oriented implementation of R-UMLDA (Uncorrelated Multilinear Discriminant Analysis w/ Regularization).\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    __init__(): Initialzies the myRUMLDA object and handles error-checking on parameters the user has entered.\n",
    "    est_largest_l_n_mode_wcs__(): Mainly for internal use. Estimate largest eigenvalue of \n",
    "    n-mode within class scatter.\n",
    "    fit(): Performs UMLDA with given arguments.\n",
    "    transform(): Returns the projected data.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.maxK: No of iterations (user-defined)\n",
    "    self.numP: The number of EMPs per TVP (user-defined)\n",
    "    self.gamma: Regularization parameter (user-defined)\n",
    "    self.sample_modes: # of modes of given dataset\n",
    "    self.sample_dims: # of modes of a sample\n",
    "    self.samples_no: # of samples\n",
    "    self.no_of_classes: # of class labels\n",
    "    self.samples_per_class: (numpy array) contains # of elemets per class\n",
    "    self.projection_matrices: 2D List (NxP) containing the projection vectors\n",
    "    self.projected_data: Coordinate vector/Projected data, shape: (no_of_samples,P)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,numP,maxK,gamma):\n",
    "        '''\n",
    "        numP: The number of EMPs in the TVP.\n",
    "        self.maxK: No of iterations (user-defined)\n",
    "        self.gamma: Regularization parameter (user-defined)\n",
    "        '''\n",
    "\n",
    "        # Error handling on input        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if int(maxK) <= 0:\n",
    "                \n",
    "                raise Exception('Max iters (k) has to be a positive integer.')\n",
    "                \n",
    "            self.maxK = maxK\n",
    "                \n",
    "        except:\n",
    "\n",
    "            raise Exception('Max iters (k) has to be a positive integer.')\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            if int(numP) <= 0:\n",
    "                \n",
    "                raise Exception('No of features (numP) has to be a positive integer.')\n",
    "                \n",
    "            self.numP = numP\n",
    "                \n",
    "        except:\n",
    "\n",
    "            raise Exception('No of features (numP) has to be a positive integer.')\n",
    "        \n",
    "        try: # Can gamma be negative?\n",
    "                            \n",
    "            self.gamma = float(gamma)\n",
    "                \n",
    "        except:\n",
    "\n",
    "            raise Exception('Gamma (reg parameter) has to be a float.')\n",
    "            \n",
    "    def est_largest_l_n_mode_wcs_(self,samples,samples_labels):\n",
    "        '''\n",
    "        Estimate largest eigenvalue of n-mode within class scatter.\n",
    "        Returns a list of eigenvalues for each mode.\n",
    "        '''\n",
    "        \n",
    "        largest_eig_per_mode = []\n",
    "        \n",
    "        for n in range(self.sample_dims):\n",
    "            \n",
    "            within_class_scatter = np.zeros((samples.shape[n],samples.shape[n]))\n",
    "            \n",
    "#             between_class_scatter = np.zeros((samples.shape[n],samples.shape[n]))\n",
    "            \n",
    "            for c in range(1,self.no_of_classes+1):\n",
    "                \n",
    "                # Find all samples with given class label\n",
    "                \n",
    "                indexes = np.where(samples_labels == c)\n",
    "                               \n",
    "                samples_of_class = samples[...,indexes]\n",
    "                \n",
    "                # Remove dims with 1 component\n",
    "\n",
    "                samples_of_class = np.squeeze(samples_of_class)\n",
    "                \n",
    "                # Find mean sample of class\n",
    "                \n",
    "                class_mean = tl.mean(samples_of_class,axis=-1)\n",
    "                \n",
    "                # Mode-n unfolding\n",
    "                \n",
    "#                 XDiff = tl.unfold(class_mean,n)\n",
    "                \n",
    "                # These samples contribute to the Between Class Scatter...\n",
    "                \n",
    "#                 between_class_scatter = between_class_scatter + len(indexes[0]) * XDiff @ np.transpose(XDiff)\n",
    "                \n",
    "                # ... and of course the Within Class Scatter\n",
    "                \n",
    "                for j in range(len(indexes[0])): # Eq. (9) [2]\n",
    "                    \n",
    "                    XDiff = tl.unfold(samples[...,indexes[0][j]],n) - tl.unfold(class_mean,n)\n",
    "\n",
    "                    within_class_scatter = within_class_scatter + XDiff @ np.transpose(XDiff)\n",
    "                \n",
    "            eigenvals, eigenvecs = np.linalg.eig(within_class_scatter)\n",
    "\n",
    "            # eig doesnt not necessarily return sorted eigenvalues, we need to sort them\n",
    "\n",
    "            indexOrd = np.argsort(eigenvals)[::-1] \n",
    "\n",
    "            eigenvals_sorted = eigenvals[indexOrd]\n",
    "            \n",
    "            largest_eig_per_mode.append(eigenvals_sorted[0])\n",
    "                \n",
    "        return largest_eig_per_mode\n",
    "        \n",
    "    def fit(self,samples,samples_labels):\n",
    "        '''\n",
    "        Performs UMLDA with given arguments.\n",
    "        samples: Input tensor of (N+1) dimensions (+1: Group input in one larger tensor)\n",
    "        samples_labels: Labels of given samples.\n",
    "        '''\n",
    "        \n",
    "        # Gather and store basic info on the train data\n",
    "    \n",
    "        self.sample_modes = len(samples.shape)\n",
    "    \n",
    "        self.sample_dims = len(samples.shape) - 1\n",
    "\n",
    "        self.samples_no = samples.shape[-1]\n",
    "        \n",
    "        self.no_of_classes = len(np.unique(samples_labels))\n",
    "        \n",
    "        self.samples_per_class = np.zeros((self.no_of_classes,1))\n",
    "  \n",
    "        for i in range(self.samples_no): # Remember: no of samples in class 80 are in self.samples_per_class[79] !\n",
    "            \n",
    "            self.samples_per_class[int(samples_labels[i])-1][0] = self.samples_per_class[int(samples_labels[i])-1][0] + 1\n",
    "        \n",
    "        ########################################################\n",
    "        # 1. Center the data\n",
    "        ########################################################\n",
    "        \n",
    "        # Find mean tensor\n",
    "        \n",
    "        self.samples_mean = np.mean(samples,axis=self.sample_dims)\n",
    "\n",
    "        # Center the data\n",
    "\n",
    "        for i in range(self.samples_no):\n",
    "\n",
    "            samples[...,i] = np.subtract(samples[...,i],self.samples_mean)\n",
    "\n",
    "        ########################################################\n",
    "        # 2. Estimate largest eigenvalue of n-mode within class scatter\n",
    "        ########################################################\n",
    "        \n",
    "        # l_e is a list of length equal to the number of sample_dims\n",
    "        # and contains the largest eigenvalue of the n-mode scatter.\n",
    "        \n",
    "        l_e = self.est_largest_l_n_mode_wcs_(samples,samples_labels)\n",
    "        \n",
    "        ########################################################\n",
    "        # 3. Projection matrix initialization\n",
    "        ########################################################\n",
    "        \n",
    "        # Create the list that will hold the projection vectors\n",
    "        # Dimensions: N x p\n",
    "        # Initialization method: Uniform\n",
    "        \n",
    "        self.projection_matrices = []\n",
    "        \n",
    "        for n in range(self.sample_dims):\n",
    "            \n",
    "            self.projection_matrices.append([])\n",
    "            \n",
    "            for p in range(self.numP):\n",
    "                \n",
    "               self.projection_matrices[n].append(np.ones((samples.shape[n],1)) / np.linalg.norm(np.ones((samples.shape[n],1))))\n",
    "         \n",
    "        ########################################################\n",
    "        # 4. UMLDA Loop\n",
    "        ########################################################\n",
    "        \n",
    "        kappa = 10e-3 # This is added during the computation of R in order to get better results pg.12 [2]\n",
    "        \n",
    "        for p in range(self.numP): # step p: Caclulate the p-th EMP\n",
    "\n",
    "            for k in range(self.maxK):\n",
    "                \n",
    "                for n in range(self.sample_dims):\n",
    "                    \n",
    "                    # Calculate the partial projection\n",
    "                    \n",
    "                    projection_modes = [*range(self.sample_dims)]\n",
    "                    \n",
    "                    projection_modes.remove(n) # Without using the current mode!\n",
    "                        \n",
    "                    projection_matrices2use = np.array(self.projection_matrices)[projection_modes,p]\n",
    "                    \n",
    "                    partial_projection = tl.tenalg.multi_mode_dot(samples,projection_matrices2use,modes=projection_modes,transpose=True) #.reshape(samples.shape[n],self.samples_no)              \n",
    "                    \n",
    "                    # Remove dims with 1 component\n",
    "                    \n",
    "                    if n == 0: partial_projection = np.squeeze(partial_projection,1)\n",
    "                    else: partial_projection = np.squeeze(partial_projection,0)\n",
    "                        \n",
    "                    # Calculate BCS and WCS\n",
    "                    \n",
    "                    between_class_scatter = np.zeros((samples.shape[n],samples.shape[n]))\n",
    "                    within_class_scatter = np.zeros((samples.shape[n],samples.shape[n]))\n",
    "                    \n",
    "                    for c in range(1,self.no_of_classes+1):\n",
    "                        \n",
    "                        indexes = np.where(samples_labels == c)[0]\n",
    "                        \n",
    "                        partial_projection_of_class_samples = partial_projection[:,indexes]\n",
    "                        \n",
    "                        class_mean = tl.mean(partial_projection_of_class_samples,axis=-1)\n",
    "                        \n",
    "                        # Eq. (7),(8) [2]\n",
    "                        \n",
    "                        for m in range(int(self.samples_per_class[c-1])): \n",
    "                            \n",
    "                            YDiff = np.subtract(partial_projection_of_class_samples[:,m],class_mean)\n",
    "                            \n",
    "                            YDiff = YDiff[...,np.newaxis] # Add one dim for numpy reasons (e.g (32,) becomes (32,1))\n",
    "                            \n",
    "                            within_class_scatter = within_class_scatter + YDiff * np.transpose(YDiff)\n",
    "                        \n",
    "                        between_class_scatter = between_class_scatter + self.samples_per_class[c-1] * class_mean[...,np.newaxis] @ np.transpose(class_mean[...,np.newaxis])\n",
    "                        \n",
    "                    within_class_scatter = within_class_scatter + self.gamma * l_e[n] * np.eye(samples.shape[n])\n",
    "                    \n",
    "                    # Update projection vectors\n",
    "                    \n",
    "                    if p > 0:\n",
    "                        \n",
    "                        invSW = np.linalg.inv(within_class_scatter)\n",
    "                        \n",
    "                        GYSYG = np.linalg.inv(np.transpose(Gps) @ np.transpose(partial_projection) @ invSW @ partial_projection @ Gps + kappa * np.eye(p))\n",
    "    \n",
    "                        RSB = np.eye(samples.shape[n]) - partial_projection @ Gps @ GYSYG @ np.transpose(Gps) @ np.transpose(partial_projection) @ invSW\n",
    "                        \n",
    "                        between_class_scatter = RSB @ between_class_scatter\n",
    "                \n",
    "                        eigenvals, eigenvecs = scipy.linalg.eig(np.linalg.inv(within_class_scatter) @ between_class_scatter)\n",
    "\n",
    "                        indexOrd = np.argsort(eigenvals)[::-1]\n",
    "\n",
    "                        eigenvecs_sorted = eigenvecs[:,indexOrd]\n",
    "\n",
    "                        respective_eigenvector = eigenvecs_sorted[:,0][...,np.newaxis]\n",
    "            \n",
    "                    else:\n",
    "            \n",
    "                        # pg.7 [2]\n",
    "    \n",
    "                        eigenvals, eigenvecs = scipy.linalg.eig(np.linalg.inv(within_class_scatter) @ between_class_scatter)\n",
    "\n",
    "                        # eig doesnt not necessarily return sorted eigenvalues, we need to sort them\n",
    "\n",
    "                        indexOrd = np.argsort(eigenvals)[::-1]\n",
    "\n",
    "                        eigenvecs_sorted = eigenvecs[:,indexOrd]\n",
    "\n",
    "                        respective_eigenvector = eigenvecs_sorted[:,0][...,np.newaxis]\n",
    "                        \n",
    "                    # In order to get consistent results, force the first component of\n",
    "                    # each eigenvector to be positive\n",
    "\n",
    "                    if respective_eigenvector[0] < 0.0:\n",
    "\n",
    "                        respective_eigenvector = respective_eigenvector * (-1)\n",
    "                        \n",
    "                    # Normalize and save eigenvector\n",
    "                    \n",
    "                    self.projection_matrices[n][p] = np.array(respective_eigenvector / np.linalg.norm(respective_eigenvector),copy=True)\n",
    "                    \n",
    "            # Update coordinate/projection vector at p\n",
    "        \n",
    "            projection_matrices2use = np.array(self.projection_matrices)[:,p]\n",
    "            \n",
    "            gp = tl.tenalg.multi_mode_dot(samples,projection_matrices2use,modes=[*range(self.sample_dims)],transpose=True)\n",
    "            \n",
    "            # Remove dims with 1 component\n",
    "            \n",
    "            gp = np.transpose(np.squeeze(gp,1))\n",
    "\n",
    "            if p == 0:\n",
    "                \n",
    "                # Gps: Coordinate vectors/projected data, shape: (no_of_samples,P)\n",
    "        \n",
    "                Gps = gp\n",
    "                \n",
    "            else:\n",
    "\n",
    "                Gps =  np.append(Gps,gp,axis=1) # Gps is in R^(p)x(M)\n",
    "               \n",
    "            # Store projected data to an attribute for easier access\n",
    "\n",
    "            self.projected_data = Gps\n",
    "        \n",
    "    def transform(self):\n",
    "        '''\n",
    "        Returns projected data.\n",
    "        '''\n",
    "\n",
    "        return self.projected_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-usage",
   "metadata": {},
   "source": [
    "---\n",
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ahead-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset dimentsions: (32, 32, 320)\n",
      "Projected dataset dimensions: (320, 10)\n",
      "\n",
      "Last 5 samples of dataset\n",
      "\n",
      "[-361.92593877 -246.27494986  320.41517831  135.47306974  205.68375144\n",
      " -193.6720902    71.90894727 -299.85391768  -29.55092469  -16.02955626]\n",
      "[ 143.13450757   89.92832496  113.58801227   34.4189721   -39.7045285\n",
      "   45.70854008  200.32569362 -186.26566352 -279.67030279  224.83590522]\n",
      "[ 225.14081183   15.62720897   46.58909169 -127.94935978   34.55952992\n",
      " -242.1742454   217.60564205 -121.22772416 -234.10596575  168.92257677]\n",
      "[ 224.20630489  149.03509764  111.75381044   25.68338882 -139.34947863\n",
      " -154.52934698   14.6833845  -316.71107775  -27.64050278  133.85848418]\n",
      "[ 397.31304374  -48.1316686   -52.10242135 -133.93373502  -70.76882787\n",
      " -179.61405104 -112.24756417  -99.68463025 -213.65845614  113.33278171]\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "\n",
    "# Create a RUMLDA object and fit the dataset\n",
    "\n",
    "rumlda = myRUMLDA(numP=10,maxK=2,gamma=0.01)\n",
    "rumlda.fit(train_set,gnd_train)\n",
    "\n",
    "# Print size of projected data\n",
    "\n",
    "print(f'Initial dataset dimentsions: {train_set.shape}')\n",
    "print(f'Projected dataset dimensions: {rumlda.projected_data.shape}')\n",
    "\n",
    "# Print last 5 samples\n",
    "\n",
    "print('\\nLast 5 samples of dataset\\n')\n",
    "\n",
    "for i in range(5,0,-1):\n",
    "    print(rumlda.projected_data[(-1)*i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-intelligence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
